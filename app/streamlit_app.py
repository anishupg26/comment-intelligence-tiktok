import os
import sys
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler

ROOT_DIR = os.path.dirname(os.path.dirname(__file__))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from theme import COLORS
from ui_components import (
    apply_theme,
    metric_card,
    insight_card,
    section_header,
    kpi_row,
    styled_container
)

THEME_COLORS = {
    "Request for more examples": "#4CAF50",
    "Concept confusion": "#FF9800",
    "Trust skepticism": "#F44336",
    "General praise": "#2196F3"
}


def normalize_theme(theme):
    mapping = {
        "clarity and examples": "clarity",
        "need for clarity and examples": "clarity",
        "request for clarity": "clarity",
        "understanding concepts": "concept understanding",
        "learning concepts": "concept understanding",
        "optimization challenges": "habit optimization",
        "optimizing habits and routines": "habit optimization",
    }
    return mapping.get(str(theme).lower().strip(), theme)


def format_percent(v):
    if pd.isna(v):
        return "â€”"
    return f"~{int(round(v, 0))}%"


def estimate_impact_metrics(priority):
    if priority == "High":
        return {
            "engagement_lift": random.uniform(18, 30),
            "view_growth": random.uniform(10, 20),
            "retention_gain": random.uniform(6, 12)
        }
    if priority == "Medium":
        return {
            "engagement_lift": random.uniform(8, 15),
            "view_growth": random.uniform(4, 9),
            "retention_gain": random.uniform(2, 5)
        }
    return {
        "engagement_lift": random.uniform(1, 5),
        "view_growth": random.uniform(0, 3),
        "retention_gain": random.uniform(0, 2)
    }


@st.cache_data(show_spinner=False)
def run_full_pipeline(df):
    df_local = df.copy()
    if "comment_text" in df_local.columns and "comment" not in df_local.columns:
        df_local = df_local.rename(columns={"comment_text": "comment"})

    results = run_analysis(
        df_local,
        text_col="comment",
        n_clusters=8,
        batch_size=100
    )

    impact_scores = results.get("impact_scores", pd.DataFrame()).copy()
    theme_mapping = {}
    if not impact_scores.empty and "cluster_id" in impact_scores.columns and "theme" in impact_scores.columns:
        theme_mapping = dict(
            zip(
                impact_scores["cluster_id"].astype(str),
                impact_scores["theme"].astype(str)
            )
        )

    clusters_df = results.get("clusters", pd.DataFrame())
    cluster_labels = []
    if not clusters_df.empty and "cluster" in clusters_df.columns:
        cluster_labels = clusters_df["cluster"].astype(str).tolist()

    actions_df = pd.DataFrame(results.get("top_insights", []))

    return {
        **results,
        "embeddings": results.get("embeddings"),
        "cluster_labels": cluster_labels,
        "theme_mapping": theme_mapping,
        "theme_metrics": impact_scores.copy(),
        "insights_df": impact_scores.copy(),
        "actions_df": actions_df
    }


def generate_executive_report(actions_df):
    report = []
    report.append("AI CREATOR COMMENT INTELLIGENCE REPORT")
    report.append("=" * 45)
    report.append("")

    if len(actions_df) == 0:
        report.append("No insights available.")
        return "\n".join(report)

    from datetime import datetime
    report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    report.append("")

    top = actions_df.sort_values("impact_score", ascending=False).iloc[0]

    report.append("TOP STRATEGIC OPPORTUNITY")
    report.append(f"Theme: {top['theme']}")
    report.append(f"Impact Score: {top['impact_score']}")
    report.append("")

    report.append("RECOMMENDED ACTION")
    if "recommended_action" in actions_df.columns and pd.notna(top.get("recommended_action")):
        report.append(str(top["recommended_action"]))
    else:
        report.append("Provide deeper explanations and structured guidance.")
    report.append("")

    report.append("EXPECTED PERFORMANCE IMPACT")
    def safe_metric(col, default):
        return top[col] if col in top and pd.notna(top[col]) else default

    report.append(f"Engagement Lift: {safe_metric('engagement_lift','Estimated positive impact')}")
    report.append(f"View Growth: {safe_metric('view_growth','Projected increase expected')}")
    report.append(f"Retention Gain: {safe_metric('retention_gain','Improved audience retention expected')}")
    report.append("")

    report.append("TOTAL THEMES ANALYZED")
    report.append(str(len(actions_df)))
    report.append("")

    report.append("Generated by AI Creator Intelligence Engine")

    return "\n".join(report)


def render_methodology_and_transparency():
    st.subheader("How Impact Score is Calculated")
    st.info(
        "Impact Score Formula:\n"
        "Impact Score =\n"
        "0.4 Ã— Comment Volume\n"
        "0.4 Ã— Engagement Potential\n"
        "0.2 Ã— Risk Severity"
    )

    st.subheader("Example Impact Score Calculation")
    st.code(
        "Comment Volume = 80\n"
        "Engagement Potential = 60\n"
        "Risk Severity = 40\n\n"
        "Impact Score =\n"
        "0.4 Ã— 80 +\n"
        "0.4 Ã— 60 +\n"
        "0.2 Ã— 40\n\n"
        "= 32 + 24 + 8\n"
        "= 64"
    )

    st.divider()

    st.subheader("Example Recommended Actions")
    st.markdown(
        "- Create a clarification video addressing common confusion\n"
        "- Pin a comment citing scientific or factual sources\n"
        "- Add visual diagram or step-by-step breakdown in next video\n"
        "- Publish FAQ addressing repeated audience questions\n"
        "- Respond with short explainer comment thread"
    )

    st.divider()

    st.subheader("System Limitations")
    st.warning(
        "Sarcasm or humor may be misinterpreted by clustering.\n"
        "Spam or bot comments may distort theme detection.\n"
        "Results should support â€” not replace â€” human judgment."
    )

    st.caption("Embedding Model Used: sentence-transformers (all-MiniLM-L6-v2)")

    st.divider()

    st.subheader("Validation Strategy")
    st.markdown(
        "This system can be validated by:\n"
        "- Manually labeling a sample of 200 comments into themes\n"
        "- Comparing clustering results with human labels\n"
        "- Measuring agreement rate and theme precision"
    )

    st.subheader("Success Metrics")
    st.markdown(
        "- Theme precision vs manually labeled dataset\n"
        "- Reduction in manual comment review time\n"
        "- Engagement improvement after implementing recommendations"
    )

    st.divider()

    st.subheader("System Workflow")
    st.markdown(
        "Upload Comments\n"
        "â†“\n"
        "Semantic Clustering\n"
        "â†“\n"
        "Theme Detection\n"
        "â†“\n"
        "Strategic Insights\n"
        "â†“\n"
        "Recommended Actions\n"
        "â†“\n"
        "Executive Report"
    )

st.set_page_config(
    page_title="AI Creator Intelligence",
    page_icon="ðŸ“Š",
    layout="wide"
)

apply_theme()
st.markdown(
    """
<style>
.block-container {
  padding-top: 1.5rem;
  padding-bottom: 1rem;
  padding-left: 2rem;
  padding-right: 2rem;
}
section.main > div { padding-top: 0rem; }
.insight-card {
  border-radius: 14px;
  padding: 22px;
  background: linear-gradient(145deg, #0e1624, #0b111c);
  border-left: 4px solid #2dd4bf;
  height: 100%;
}
.card-title {
  font-size: 14px;
  opacity: 0.75;
  margin-bottom: 6px;
}
.card-impact {
  font-size: 28px;
  font-weight: 700;
  margin-bottom: 12px;
}
.card-metrics {
  font-size: 13px;
  line-height: 1.6;
  opacity: 0.85;
}
</style>
""",
    unsafe_allow_html=True
)

# -------------------------------
# HEADER
# -------------------------------

st.title("AI Creator Comment Intelligence Engine")
st.caption("Turn messy audience comments into ranked strategic opportunities")

st.divider()

# -------------------------------
# SIDEBAR NAVIGATION
# -------------------------------

st.sidebar.title("Navigation")

page = st.sidebar.radio(
    "Go to",
    [
        "Upload & Analyze",
        "Strategic Insights",
        "Cluster Explorer",
        "Action Recommendations",
        "Executive Summary"
    ]
)

st.sidebar.divider()
st.sidebar.markdown("---")

st.sidebar.subheader("Project Info")
st.sidebar.write("Version: v1.0")
st.sidebar.write("Mode: Private")
st.sidebar.write("Model: Semantic Clustering")
st.sidebar.checkbox("Debug", value=False, key="debug")


from intelligence.pipeline import run_analysis


def render_upload_page():
    st.header("Upload Audience Comments")

    def _normalize_col(name):
        return str(name).strip().lower().replace(" ", "_")

    def _dedupe_columns(df):
        cols = []
        counts = {}
        for col in df.columns:
            if col not in counts:
                counts[col] = 0
                cols.append(col)
            else:
                counts[col] += 1
                cols.append(f"{col}_{counts[col]}")
        df.columns = cols
        return df

    def detect_schema(df):
        schema = {}
        comment_candidates = ["comment", "text", "body", "content", "message", "comment_text"]
        likes_candidates = ["likes", "like_count", "engagement"]
        sentiment_candidates = ["sentiment", "score"]
        timestamp_candidates = ["timestamp", "time", "created_at", "date"]
        author_candidates = ["author", "user", "user_id", "uid", "author_id"]

        present_comment = [c for c in comment_candidates if c in df.columns]
        if len(present_comment) == 1:
            schema["comment_text"] = present_comment[0]
        elif len(present_comment) > 1:
            schema["comment_text"] = present_comment[0]

        for c in likes_candidates:
            if c in df.columns:
                schema["likes"] = c
                break
        for c in sentiment_candidates:
            if c in df.columns:
                schema["sentiment"] = c
                break
        for c in timestamp_candidates:
            if c in df.columns:
                schema["timestamp"] = c
                break
        for c in author_candidates:
            if c in df.columns:
                schema["author"] = c
                break

        return schema, len(present_comment)

    def validate_schema(df, schema):
        if "comment_text" not in schema or schema["comment_text"] not in df.columns:
            return False, "No comment text column detected"
        return True, ""

    def clean_dataset(df, schema):
        df = df.copy()
        rows_before = len(df)
        df = df.dropna(subset=[schema["comment_text"]])
        rows_after = len(df)

        if "likes" in schema and schema["likes"] in df.columns:
            df[schema["likes"]] = df[schema["likes"]].fillna(0)
        if "sentiment" in schema and schema["sentiment"] in df.columns:
            df[schema["sentiment"]] = df[schema["sentiment"]].fillna(0)

        rename_map = {schema["comment_text"]: "comment_text"}
        if "likes" in schema:
            rename_map[schema["likes"]] = "likes"
        if "sentiment" in schema:
            rename_map[schema["sentiment"]] = "sentiment"
        if "timestamp" in schema:
            rename_map[schema["timestamp"]] = "timestamp"
        if "author" in schema:
            rename_map[schema["author"]] = "author"

        df_canonical = df.rename(columns=rename_map)
        return df_canonical, rows_before, rows_after

    def ingest_dataset(uploaded_file):
        df_raw = pd.read_csv(uploaded_file)
        df_raw.columns = [_normalize_col(c) for c in df_raw.columns]
        df_raw = _dedupe_columns(df_raw)

        schema, comment_candidates = detect_schema(df_raw)
        if comment_candidates != 1:
            st.warning("Multiple possible comment text columns detected. Please confirm.")
            cols = df_raw.columns.tolist()
            schema["comment_text"] = st.selectbox(
                "Comment text column",
                cols,
                index=cols.index(schema.get("comment_text", cols[0])) if cols else 0
            )

        if "likes" in df_raw.columns:
            if "likes" not in schema:
                schema["likes"] = "likes"
        if "sentiment" in df_raw.columns:
            if "sentiment" not in schema:
                schema["sentiment"] = "sentiment"

        valid, error = validate_schema(df_raw, schema)
        if not valid:
            st.error(error)
            return None, None

        df_canonical, before, after = clean_dataset(df_raw, schema)

        if not pd.api.types.is_string_dtype(df_canonical["comment_text"]):
            st.error("Mapped comment column is not text. Please select the correct column.")
            return None, None

        feedback = {
            "rows_loaded": before,
            "rows_dropped": before - after,
            "detected_columns": schema,
            "mapping_used": {k: v for k, v in schema.items()}
        }
        return df_canonical, feedback

    uploaded_file = st.file_uploader(
        "Upload CSV of comments",
        type=["csv"]
    )

    if uploaded_file:
        cleaned_df, feedback = ingest_dataset(uploaded_file)
        if cleaned_df is None:
            return

        st.success("File uploaded successfully")

        st.subheader("Detected Schema")
        st.write(f"Rows loaded: {feedback['rows_loaded']}")
        st.write(f"Rows dropped: {feedback['rows_dropped']}")
        st.write(f"Detected columns: {feedback['detected_columns']}")
        st.write(f"Mapping used: {feedback['mapping_used']}")
        if st.session_state.get("debug"):
            st.write(f"Unique themes (if present): {cleaned_df.get('theme', pd.Series([])).nunique()}")
            st.write(f"Sample comment_text: {cleaned_df['comment_text'].dropna().head(1).tolist()}")

        if len(cleaned_df) > 1500:
            st.info("Large dataset detected â€” optimized processing enabled")

        processing_mode = st.radio(
            "Processing scope",
            ["Process full dataset", "Process first N rows"],
            horizontal=True
        )
        max_rows = None
        if processing_mode == "Process first N rows":
            max_rows = st.number_input(
                "Rows to process",
                min_value=100,
                max_value=len(cleaned_df),
                value=min(2000, len(cleaned_df)),
                step=100
            )

        st.subheader("Preview")
        preview_df = cleaned_df.head(max_rows) if max_rows else cleaned_df
        st.dataframe(preview_df, width="stretch")

        st.divider()

        if st.session_state.get("max_rows") != max_rows:
            st.session_state.pop("analysis_results", None)
            st.session_state["max_rows"] = max_rows

        if st.button("Run Intelligence Engine"):
            try:
                upload_df = cleaned_df.head(int(max_rows)) if max_rows else cleaned_df
                with st.spinner("Analyzing audience intelligence..."):
                    results = run_full_pipeline(upload_df)
                st.session_state["results"] = results
                st.session_state["analysis_results"] = results
                st.success("Analysis complete")

                perf = results.get("performance", {})
                if perf:
                    st.subheader("Performance Metrics")
                    st.write(f"Total rows processed: {perf.get('total_rows', 0)}")
                    st.write(f"Total time: {perf.get('total_time', 0):.2f}s")
                    st.write(f"Rows per second: {perf.get('rows_per_second', 0):.2f}")
                    if perf.get("embedding_time") is not None:
                        st.write(f"Embedding time: {perf.get('embedding_time', 0):.2f}s")
                if perf.get("clustering_time") is not None:
                    st.write(f"Clustering time: {perf.get('clustering_time', 0):.2f}s")
            except Exception as exc:
                st.error(f"Processing failed: {exc}")
                return


def render_strategic_insights():
    st.header("Top Strategic Signals")

    analysis_results = st.session_state.get("analysis_results")
    if not analysis_results:
        st.warning("Run analysis first")
        st.stop()

    col1, col2, col3 = st.columns(3)

    with col1:
        insight_card(
            "Top Growth Opportunity",
            "Requests for deeper explanation and more detailed examples from the creator",
            tag="Opportunity",
            accent=COLORS["accent"]
        )

    with col2:
        insight_card(
            "Primary Risk Signal",
            "Confusion about topic due to unclear explanation or missing conceptual breakdown",
            tag="Risk",
            accent=COLORS["warning"]
        )

    with col3:
        insight_card(
            "Engagement Driver",
            "Positive reinforcement and appreciation of creator style and delivery",
            tag="Momentum",
            accent=COLORS["info"]
        )

    st.divider()

    impact_scores_raw = analysis_results["impact_scores"].copy()
    impact_scores = impact_scores_raw.rename(columns={
        "theme": "Theme",
        "impact_score": "Impact Score",
        "risk_score": "Risk Score",
        "priority": "Priority",
        "comment_count": "Comment Count"
    })
    impact_scores["Theme"] = (
        impact_scores["Theme"].astype(str).str.strip().str.lower().str.replace(r"\\s+", " ", regex=True)
    )
    impact_scores["Theme"] = impact_scores["Theme"].apply(normalize_theme)
    impact_scores["Theme_display"] = impact_scores["Theme"].str.title()
    impact_scores = (
        impact_scores.groupby("Theme", as_index=False)
        .agg({
            "Impact Score": "mean",
            "Risk Score": "mean",
            "Comment Count": "sum",
            "Priority": "first"
        })
    )
    missing_priority = impact_scores["Priority"].isna().sum()
    if missing_priority > 0:
        if st.session_state.get("debug"):
            st.write(f"Missing priority count: {missing_priority}")
        def _priority(impact, risk):
            if pd.isna(impact) or pd.isna(risk):
                return "Medium"
            if impact >= 200 or risk >= 80:
                return "High"
            if impact >= 100 or risk >= 50:
                return "Medium"
            return "Low"
        impact_scores["Priority"] = impact_scores.apply(
            lambda r: _priority(r["Impact Score"], r["Risk Score"]),
            axis=1
        )
    impact_scores["Theme_display"] = impact_scores["Theme"].str.title()
    impact_scores["Engagement Weight"] = impact_scores["Comment Count"].astype(float)
    if st.session_state.get("debug"):
        st.write(f"Unique themes: {impact_scores['Theme'].nunique()}")
        clusters_debug = analysis_results.get("clusters")
        if clusters_debug is not None and "comment" in clusters_debug.columns:
            st.write(f"Sample comment_text: {clusters_debug['comment'].dropna().head(1).tolist()}")

    total_comments = int(impact_scores["Comment Count"].sum())
    total_themes = int(impact_scores["Theme"].nunique())
    dominant_share = (
        impact_scores["Impact Score"].max()
        / max(impact_scores["Impact Score"].sum(), 1)
        * 100
    )
    avg_impact = float(impact_scores["Impact Score"].mean())
    high_priority_count = int((impact_scores["Priority"] == "High").sum())

    kpi_row([
        {
            "label": "Total Comments",
            "value": f"{total_comments}",
            "accent": COLORS["accent"]
        },
        {
            "label": "Total Themes",
            "value": f"{total_themes}",
            "accent": COLORS["info"]
        },
        {
            "label": "Dominant Theme Share",
            "value": f"{dominant_share:.1f}%",
            "accent": COLORS["purple"]
        },
        {
            "label": "Avg Impact Score",
            "value": f"{avg_impact:.1f}",
            "accent": COLORS["warning"]
        },
        {
            "label": "High Priority Count",
            "value": f"{high_priority_count}",
            "accent": COLORS["danger"]
        }
    ])

    chart_left, chart_right = st.columns(2)

    with chart_left:
        bar_fig = px.bar(
            impact_scores,
            x="Theme_display",
            y="Impact Score",
            color="Theme_display",
            color_discrete_map=THEME_COLORS,
            title="Theme Distribution by Impact",
            template="plotly_dark"
        )
        bar_fig.update_layout(showlegend=False, margin=dict(l=10, r=10, t=40, b=20))
        bar_fig.update_xaxes(showgrid=True)
        bar_fig.update_yaxes(showgrid=True)
        st.plotly_chart(bar_fig, width="stretch")

    with chart_right:
        bubble_fig = px.scatter(
            impact_scores,
            x="Impact Score",
            y="Risk Score",
            size="Engagement Weight",
            color="Theme_display",
            color_discrete_map=THEME_COLORS,
            hover_data=[
                "Theme_display",
                "Impact Score",
                "Risk Score",
                "Engagement Weight",
                "Priority",
                "Comment Count"
            ],
            title="Impact vs Risk (Engagement Weighted)",
            template="plotly_dark"
        )
        bubble_fig.update_layout(margin=dict(l=10, r=10, t=40, b=20))
        bubble_fig.update_xaxes(showgrid=True)
        bubble_fig.update_yaxes(showgrid=True)
        st.plotly_chart(bubble_fig, width="stretch")

    impact_scores["Priority"] = impact_scores["Priority"].fillna("Medium")
    priority_counts = impact_scores["Priority"].value_counts().reset_index()
    priority_counts.columns = ["Priority", "Count"]

    donut_fig = px.pie(
        priority_counts,
        values="Count",
        names="Priority",
        hole=0.5,
        title="Priority Distribution",
        template="plotly_dark"
    )
    donut_fig.update_layout(margin=dict(l=10, r=10, t=40, b=10))
    st.plotly_chart(donut_fig, width="stretch")

    section_header("Opportunity Ranking", "Ranked by impact score and priority strength")

    styled_table = impact_scores[["Theme_display", "Impact Score", "Priority"]].style.background_gradient(
        subset=["Impact Score"],
        cmap="YlGn"
    )
    st.dataframe(styled_table, width="stretch")

    st.divider()
    st.subheader("Why this insight exists")

    clusters_df = analysis_results.get("clusters")
    cluster_metrics = analysis_results.get("cluster_metrics")
    embeddings_2d = analysis_results.get("embeddings_2d")
    impact_scores_raw = analysis_results.get("impact_scores")

    if impact_scores_raw is not None and not impact_scores_raw.empty:
        impact_scores_view = impact_scores_raw.copy()
        impact_scores_view["theme_norm"] = impact_scores_view["theme"].astype(str).apply(normalize_theme)
        theme_options = impact_scores_view["theme_norm"].astype(str).tolist()
        selected_theme = st.selectbox("Select theme/cluster", theme_options)
        selected_row = impact_scores_view[impact_scores_view["theme_norm"].astype(str) == selected_theme].iloc[0]
        cluster_id = selected_row.get("cluster_id")

        if clusters_df is not None and embeddings_2d is not None:
            if "comment" in clusters_df.columns:
                clusters_df["comment"] = clusters_df["comment"].astype(str).str.strip().str.slice(0, 180)
            if "comment" in embeddings_2d.columns:
                embeddings_2d["comment"] = embeddings_2d["comment"].astype(str).str.strip().str.slice(0, 180)
            cluster_comments = clusters_df[clusters_df["cluster"] == cluster_id]["comment"].astype(str).tolist()
            cluster_points = embeddings_2d[embeddings_2d["cluster"] == cluster_id].copy()
        else:
            cluster_comments = []
            cluster_points = None

        with st.expander("Drivers", expanded=True):
            if cluster_comments:
                tfidf = TfidfVectorizer(max_features=10, stop_words="english")
                tfidf_matrix = tfidf.fit_transform(cluster_comments)
                scores = tfidf_matrix.mean(axis=0).A1
                terms = tfidf.get_feature_names_out()
                top_terms = sorted(zip(terms, scores), key=lambda x: x[1], reverse=True)
                st.write([t for t, _ in top_terms])
            else:
                st.info("No comments available for this cluster.")

        with st.expander("Evidence", expanded=True):
            if cluster_points is not None and not cluster_points.empty:
                centroid = cluster_points[["x", "y"]].mean().to_numpy()
                distances = np.linalg.norm(cluster_points[["x", "y"]].to_numpy() - centroid, axis=1)
                cluster_points = cluster_points.assign(distance=distances)
                rep = cluster_points.sort_values("distance").head(5)
                st.dataframe(rep[["comment", "likes", "sentiment"]], width="stretch")
            else:
                st.info("No embedding data available.")

        with st.expander("Impact math", expanded=True):
            volume_weight = float(selected_row.get("comment_count", 0))
            engagement_weight = 1.0
            sentiment_weight = 1.0
            if cluster_metrics is not None and cluster_id in cluster_metrics["cluster"].values:
                metrics_row = cluster_metrics[cluster_metrics["cluster"] == cluster_id].iloc[0]
                engagement_weight = float(metrics_row.get("avg_likes", 0)) + 1.0
                sentiment_weight = float(metrics_row.get("avg_sentiment", 0)) + 1.0

            impact_calc = volume_weight * engagement_weight * sentiment_weight
            st.write("impact = volume_weight * engagement_weight * sentiment_weight")
            st.write(f"volume_weight = {volume_weight:.2f}")
            st.write(f"engagement_weight = {engagement_weight:.2f}")
            st.write(f"sentiment_weight = {sentiment_weight:.2f}")
            st.write(f"impact = {impact_calc:.2f}")

def render_cluster_explorer():
    st.markdown(
        "<h2 style='margin-bottom:10px;'>Audience Theme Clusters</h2>",
        unsafe_allow_html=True
    )

    analysis_results = st.session_state.get("analysis_results")
    if not analysis_results:
        st.warning("Run analysis first")
        st.stop()

    cluster_df = analysis_results["embeddings_2d"].copy()
    if "comment" in cluster_df.columns:
        cluster_df["comment"] = cluster_df["comment"].astype(str).str.strip().str.slice(0, 180)
    cluster_metrics = analysis_results["cluster_metrics"].copy()
    keywords = analysis_results["keywords"]

    cluster_options = sorted(cluster_df["cluster"].astype(str).unique().tolist())
    selected_clusters = st.multiselect(
        "Filter clusters",
        cluster_options,
        default=cluster_options
    )

    filtered_df = cluster_df[cluster_df["cluster"].astype(str).isin(selected_clusters)]

    embed_fig = px.scatter(
        filtered_df,
        x="x",
        y="y",
        color="cluster",
        hover_data=["comment", "likes", "sentiment"],
        title="Audience Comment Embedding Map",
        template="plotly_dark"
    )
    embed_fig.update_xaxes(showgrid=True)
    embed_fig.update_yaxes(showgrid=True)
    st.plotly_chart(embed_fig, width="stretch")

    cluster = st.selectbox(
        "Select cluster to investigate",
        cluster_options
    )

    selected_df = filtered_df[filtered_df["cluster"].astype(str) == cluster]
    if selected_df.empty:
        selected_df = cluster_df[cluster_df["cluster"].astype(str) == cluster]

    middle_left, middle_right = st.columns(2)

    with middle_left:
        metrics_row = cluster_metrics[
            cluster_metrics["cluster"].astype(str) == cluster
        ]
        if not metrics_row.empty:
            metrics_row = metrics_row.iloc[0]
            metric_card("Cluster Size", f"{metrics_row['cluster_size']:.0f}", accent=COLORS["info"])
            metric_card("Average Likes", f"{metrics_row['avg_likes']:.1f}", accent=COLORS["accent"])
            metric_card("Average Sentiment", f"{metrics_row['avg_sentiment']:.2f}", accent=COLORS["purple"])
            metric_card("Engagement Std Dev", f"{metrics_row['engagement_std']:.1f}", accent=COLORS["warning"])
        else:
            metric_card("Cluster Size", "0", accent=COLORS["info"])
            metric_card("Average Likes", "0.0", accent=COLORS["accent"])
            metric_card("Average Sentiment", "0.00", accent=COLORS["purple"])
            metric_card("Engagement Std Dev", "0.0", accent=COLORS["warning"])

    with middle_right:
        cluster_keywords = keywords.get(str(cluster), [])
        if cluster_keywords:
            keyword_df = pd.DataFrame(cluster_keywords).sort_values(
                "importance",
                ascending=True
            )
        else:
            keyword_df = pd.DataFrame({"keyword": [], "importance": []})

        if not keyword_df.empty:
            keyword_fig = px.bar(
                keyword_df,
                x="importance",
                y="keyword",
                orientation="h",
                title="Keyword Importance",
                template="plotly_dark"
            )
            keyword_fig.update_xaxes(showgrid=True)
            keyword_fig.update_yaxes(showgrid=True)
            st.plotly_chart(keyword_fig, width="stretch")
        else:
            st.info("No keyword signals available for this cluster.")

    bottom_left, bottom_right = st.columns(2)

    with bottom_left:
        box_fig = px.box(
            selected_df,
            y="likes",
            title="Engagement Distribution",
            template="plotly_dark"
        )
        box_fig.update_yaxes(showgrid=True)
        st.plotly_chart(box_fig, width="stretch")

    with bottom_right:
        st.subheader("Representative Comments")
        st.dataframe(
            selected_df[["comment", "likes", "sentiment"]].head(10),
            width="stretch"
        )


def render_action_recommendations():
    st.markdown(
        "<h2 style='margin-bottom:10px;'>Recommended Creator Actions</h2>",
        unsafe_allow_html=True
    )

    analysis_results = st.session_state.get("analysis_results")
    if not analysis_results:
        st.warning("Run analysis first")
        st.stop()

    insights = analysis_results["top_insights"]
    actions = pd.DataFrame(insights)
    if actions.empty:
        st.warning("No action recommendations generated.")
        return

    actions["theme"] = actions["theme"].astype(str).str.strip().str.lower()
    actions["theme"] = actions["theme"].apply(normalize_theme)
    actions = actions.drop_duplicates(subset=["theme"])

    actions = actions.rename(columns={
        "recommended_action": "Action",
        "impact_estimate": "Expected Impact"
    })

    actions["Effort Level"] = actions["Expected Impact"].apply(
        lambda v: "High" if v >= 200 else "Medium" if v >= 100 else "Low"
    )
    actions["Predicted Engagement Lift"] = (actions["Expected Impact"] * 0.1).round(1)
    actions["Priority"] = actions["Expected Impact"].apply(
        lambda v: "High" if v >= 200 else "Medium" if v >= 100 else "Low"
    )

    estimates = actions["Priority"].apply(estimate_impact_metrics)
    actions["engagement_lift"] = estimates.apply(lambda x: round(x["engagement_lift"], 1))
    actions["view_growth"] = estimates.apply(lambda x: round(x["view_growth"], 1))
    actions["retention_gain"] = estimates.apply(lambda x: round(x["retention_gain"], 1))

    for col in ["engagement_lift", "view_growth", "retention_gain"]:
        if col not in actions.columns:
            actions[col] = 0
    actions[["engagement_lift", "view_growth", "retention_gain"]] = (
        actions[["engagement_lift", "view_growth", "retention_gain"]]
        .fillna(0)
    )

    actions = actions.sort_values("Expected Impact", ascending=False)
    card_cols = st.columns(3, gap="large")
    for idx, row in actions.head(3).iterrows():
        with card_cols[idx % 3]:
            predicted_lift = row.get("engagement_lift", 0.0)
            predicted_view = row.get("view_growth", 0.0)
            predicted_retention = row.get("retention_gain", 0.0)
            content = (
                f"<div class='insight-card'>"
                f"<div class='card-title'>{row['Action']}</div>"
                f"<div class='card-impact'>{row['Expected Impact']} impact</div>"
                f"<div class='card-metrics'>Engagement lift: {format_percent(predicted_lift)}</div>"
                f"<div class='card-metrics'>View growth: {format_percent(predicted_view)}</div>"
                f"<div class='card-metrics'>Retention gain: {format_percent(predicted_retention)}</div>"
                f"</div>"
            )
            styled_container(content, accent=COLORS["accent"])

    st.markdown("<div style='height:25px'></div>", unsafe_allow_html=True)
    pred_chart = px.bar(
        actions,
        x="theme",
        y="engagement_lift",
        title="Predicted Engagement Lift by Theme",
        template="plotly_dark"
    )
    pred_chart.update_xaxes(showgrid=True)
    pred_chart.update_yaxes(showgrid=True)
    st.plotly_chart(pred_chart, width="stretch")

    st.markdown("<div style='height:25px'></div>", unsafe_allow_html=True)
    action_fig = px.bar(
        actions,
        x="Action",
        y="Expected Impact",
        color="Priority",
        title="Action Impact Comparison",
        template="plotly_dark"
    )
    action_fig.update_xaxes(showgrid=True)
    action_fig.update_yaxes(showgrid=True)
    st.plotly_chart(action_fig, width="stretch")

    impact_scores = analysis_results["impact_scores"].copy()
    if not impact_scores.empty and "impact_score" in impact_scores.columns and "risk_score" in impact_scores.columns:
        impact_series = pd.to_numeric(impact_scores["impact_score"], errors="coerce")
        risk_series = pd.to_numeric(impact_scores["risk_score"], errors="coerce")
        if impact_series.notna().sum() > 0 and risk_series.notna().sum() > 0:
            impact_bins = pd.qcut(
                impact_series,
                4,
                duplicates="drop"
            )
            risk_bins = pd.qcut(
                risk_series,
                4,
                duplicates="drop"
            )
            heatmap_df = pd.DataFrame({
                "impact_bin": impact_bins.cat.codes,
                "risk_bin": risk_bins.cat.codes
            }).replace(-1, np.nan).dropna()
            heatmap_data = (
                heatmap_df.groupby(["risk_bin", "impact_bin"])
                .size()
                .unstack(fill_value=0)
                .reindex(index=[0, 1, 2, 3], columns=[0, 1, 2, 3], fill_value=0)
                .to_numpy()
            )
        else:
            heatmap_data = np.zeros((0, 0))
    else:
        heatmap_data = np.zeros((0, 0))
    if heatmap_data.size == 0:
        st.info("Insufficient data to compute severity heatmap.")
    else:
        scaler = MinMaxScaler()
        flat = heatmap_data.reshape(-1, 1)
        heatmap_values = scaler.fit_transform(flat).reshape(heatmap_data.shape)
        heatmap_fig = px.imshow(
            heatmap_values,
            color_continuous_scale="Reds",
            title="Risk Mitigation Severity Heatmap",
            template="plotly_dark",
            labels={"x": "Risk Type", "y": "Mitigation Level", "color": "Severity"}
        )
        heatmap_fig.update_xaxes(showgrid=False)
        heatmap_fig.update_yaxes(showgrid=False)
        st.plotly_chart(heatmap_fig, width="stretch")


def render_executive_summary():
    st.markdown(
        "<h2 style='margin-bottom:10px;'>Executive Decision Brief</h2>",
        unsafe_allow_html=True
    )

    analysis_results = st.session_state.get("analysis_results")
    if not analysis_results:
        st.warning("Run analysis first")
        st.stop()

    def generate_executive_summary(actions_df):
        if actions_df.empty:
            return "Insufficient data to generate executive summary."
        top_row = actions_df.sort_values("Expected Impact", ascending=False).iloc[0]
        theme = str(top_row.get("theme", "")).upper() or "UNKNOWN"
        engagement_lift = format_percent(top_row.get("engagement_lift", np.nan))
        impact_score = top_row.get("Expected Impact", 0)
        recommended_action = top_row.get("Action", "Refine creator strategy.")
        return (
            f"Audience feedback shows the largest opportunity in {theme}. "
            f"Improving explanatory depth could increase engagement by {engagement_lift}. "
            f"Estimated impact score is {int(round(impact_score, 0))}. "
            f"Recommended action: {recommended_action}."
        )

    impact_scores = analysis_results["impact_scores"].copy()
    top_insights = analysis_results["top_insights"]

    if impact_scores.empty or not top_insights:
        st.warning("Insufficient analysis data for executive summary.")
        return

    top_opportunity = impact_scores.sort_values(
        "impact_score",
        ascending=False
    ).iloc[0]
    top_risk = impact_scores.sort_values(
        "risk_score",
        ascending=False
    ).iloc[0]
    primary_move = top_insights[0]

    top_left, top_mid, top_right = st.columns(3)

    with top_left:
        styled_container(
            "<div class='ci-label'>Primary Opportunity</div>"
            f"<div class='ci-value'>{top_opportunity['theme']}</div>"
            f"<div class='ci-body'>Impact score: {top_opportunity['impact_score']:.1f}</div>",
            accent=COLORS["accent"]
        )

    with top_mid:
        styled_container(
            "<div class='ci-label'>Primary Risk</div>"
            f"<div class='ci-value'>{top_risk['theme']}</div>"
            f"<div class='ci-body'>Risk score: {top_risk['risk_score']:.1f}</div>",
            accent=COLORS["danger"]
        )

    with top_right:
        styled_container(
            "<div class='ci-label'>Strategic Move</div>"
            f"<div class='ci-value'>{primary_move.get('recommended_action', 'Focused Action')}</div>"
            f"<div class='ci-body'>{primary_move.get('problem', '')}</div>",
            accent=COLORS["info"]
        )

    growth_value = min(float(top_opportunity["impact_score"]) / 3, 100)
    gauge_fig = go.Figure(
        go.Indicator(
            mode="gauge+number",
            value=growth_value,
            title={"text": "Expected Growth Impact"},
            gauge={
                "axis": {"range": [0, 100]},
                "bar": {"color": COLORS["accent"]},
                "steps": [
                    {"range": [0, 40], "color": "#1F2937"},
                    {"range": [40, 70], "color": "#374151"},
                    {"range": [70, 100], "color": "#4B5563"}
                ]
            }
        )
    )
    gauge_fig.update_layout(template="plotly_dark", margin=dict(l=10, r=10, t=40, b=10))
    st.plotly_chart(gauge_fig, width="stretch")

    styled_container(
        "<div class='ci-value'>Decision Priority: HIGH</div>"
        "<div class='ci-body'>Proceed with creator education focus within next release cycle.</div>",
        accent=COLORS["warning"],
        muted=True
    )

    actions_df = pd.DataFrame(top_insights)
    if not actions_df.empty:
        actions_df["theme"] = actions_df["theme"].astype(str).str.strip().str.lower().apply(normalize_theme)
        actions_df = actions_df.rename(columns={
            "recommended_action": "Action",
            "impact_estimate": "Expected Impact"
        })
        actions_df["Priority"] = actions_df["Expected Impact"].apply(
            lambda v: "High" if v >= 200 else "Medium" if v >= 100 else "Low"
        )
        estimates = actions_df["Priority"].apply(estimate_impact_metrics)
        actions_df["engagement_lift"] = estimates.apply(lambda x: round(x["engagement_lift"], 1))

        summary_text = generate_executive_summary(actions_df)
        st.write(summary_text)

    st.markdown("### Export Report")
    st.markdown("Generate a shareable strategic summary for stakeholders.")
    report_text = generate_executive_report(impact_scores)
    st.download_button(
        label="Download Executive Report",
        data=report_text,
        file_name="creator_strategy_report.txt",
        mime="text/plain"
    )

    st.divider()
    render_methodology_and_transparency()


# -------------------------------
# ROUTER
# -------------------------------

if page == "Upload & Analyze":
    render_upload_page()
elif page == "Strategic Insights":
    render_strategic_insights()
elif page == "Cluster Explorer":
    render_cluster_explorer()
elif page == "Action Recommendations":
    render_action_recommendations()
elif page == "Executive Summary":
    render_executive_summary()
